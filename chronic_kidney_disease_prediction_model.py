# -*- coding: utf-8 -*-
"""Chronic Kidney Disease Prediction Model.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1TI3SI2aWr9zM3oJMxmSqCLE5Rz2a3s_x
"""

# Description: This program classifies patients as having chronic kidney disease (ckd) or not using Artificial Neural Networks (ANN)
#Used this tutorial: https://www.youtube.com/watch?v=uxMvHSUOZzc&t=1083s

#import libraries
import glob
from keras.models import Sequential, load_model
import numpy as np
import pandas as pd
from keras.layers import Dense
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder, MinMaxScaler
import matplotlib.pyplot as plt
import keras as k

#load the data
from google.colab import files
uploaded = files.upload()

df = pd.read_csv('kidney_disease.csv')

#Print the first 5 rows
df.head()

#Get the shape of the data (the number of rows & cols)
df.shape

#Create a list of column names to keep
columns_to_retain = ['sg', 'al', 'sc', 'hemo', 'pcv', 'wbcc', 'rbcc', 'htn', 'classification']

#Drop the columns that are not in columns_to_retain
df = df.drop( [col for col in df.columns if not col in columns_to_retain] , axis=1 )

#Drop the rows with na or missing values
df = df.dropna(axis=0)

#Transform the non-numeric data in the columns
for column in df.columns:
  if df[column].dtype == np.number:
    continue
  df[column] = LabelEncoder().fit_transform( df[column] )

#Print the first 5 rows of the new cleaned data set
df.head()

#Split the data into independent (X) dataset (the features) and dependent (y) dataset (the target)
X = df.drop(['classification'], axis=1)
y = df['classification']

#Feature Scaling
#min-max scaler method scales the dataset so that all the input features lie between 0 and 1
x_scaler = MinMaxScaler()
x_scaler.fit(X)
column_names = X.columns
X[column_names] = x_scaler.transform(X)

#Split the data into 80% training and 20% testing & shuffle
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, shuffle=True)

#Build the model (ANN)
model = Sequential()
model.add( Dense(256, input_dim= len(X.columns) , kernel_initializer= k.initializers.random_normal(seed=13), activation='relu') )
model.add( Dense(1, activation='hard_sigmoid') )

#Compile the model
model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])

#Train the model
history = model.fit(X_train, y_train, epochs = 2000, batch_size= X_train.shape[0])

#Save the model
model.save('ckd.model')

#Visualize the models loss and accuracy
plt.plot(history.history['accuracy'])
plt.plot(history.history['loss'])
plt.title('model accuracy & loss')
plt.ylabel('accuracy and loss')
plt.xlabel('epoch')

#Get the shape of the testing and training data set
print('shape of training data:' , X_train.shape)
print('shape of test data:' , X_test.shape)

#Show the actual and predicted values
pred = model.predict(X_test)
pred = [1 if y>=0.5 else 0 for y in pred]


print('Original ; {0}'.format(", " .join(str(x) for x in y_test)))
print('Predicted ; {0}'.format(", " .join(str(x) for x in pred)))
